"""
DESAFIO 1 ‚Äî Caminho de Valor M√°ximo

Objetivo: encontrar a sequ√™ncia de habilidades (do estado atual at√© S6) que maximize o Valor
Esperado sob restri√ß√µes T ‚â§ 350h e Cumulativo de Complexidade C ‚â§ 30.

Exig√™ncias t√©cnicas:
‚Ä¢ Modelar como DP (knapsack multidimensional: tempo e complexidade).
‚Ä¢ Introduzir incerteza: simular V ~ Uniforme[V-10%, V+10%] em 1000 cen√°rios (Monte Carlo).
‚Ä¢ Maximizar E[Valor total] e relatar desvio-padr√£o dos resultados.
‚Ä¢ Gerar tamb√©m a solu√ß√£o determin√≠stica (sem incerteza) e comparar.
"""

import numpy as np
import time
import tracemalloc
from typing import Dict, List, Tuple, Any, Set, Optional
from collections import defaultdict

try:
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("‚ö†Ô∏è Matplotlib n√£o dispon√≠vel - gr√°ficos desabilitados")

from gs_config import (SKILLS_DATABASE, MAX_TIME, MAX_COMPLEXITY,
                       TARGET_SKILL, N_MONTE_CARLO, print_header, GLOBAL_SEED,
                       TEMPO_MIN, COMPLEXIDADE_MIN, USE_RELAXED_CONSTRAINTS)


class ImprovedMaxValuePathDP:
    """
    Solver otimizado com DP para knapsack multidimensional.

    ALGORITMO DP - Knapsack Multidimensional:

    Estado: dp[(t, c)] = lista de {valor, skills, path}

    Transi√ß√£o:
    Para cada skill s em ordem topol√≥gica:
        Para cada estado (t, c):
            Se pr√©-requisitos satisfeitos:
                novo_estado = (t + T[s], c + C[s])
                Se novo_estado vi√°vel:
                    Adiciona {valor + V[s], skills ‚à™ {s}, path + [s]}

    Complexidade: O(n √ó T √ó C √ó k) onde k = estados por c√©lula
    Espa√ßo: O(T √ó C √ó k)
    """

    def __init__(self, skills_db: Dict, target: str, max_states_per_cell: int = 50):
        self.skills_db = skills_db
        self.target = target
        self.max_states_per_cell = max_states_per_cell
        self.required_skills = self._get_required_skills()
        self.min_feasible_time, self.min_feasible_complexity = self._calculate_minimum_path()

    def _get_required_skills(self) -> List[str]:
        """Obt√©m todas as habilidades necess√°rias para atingir o alvo."""
        required = set()
        to_process = [self.target]

        while to_process:
            skill = to_process.pop()
            if skill in required:
                continue
            required.add(skill)
            to_process.extend(self.skills_db[skill]['Pre_Reqs'])

        return list(required)

    def _topological_sort(self) -> List[str]:
        """Ordena√ß√£o topol√≥gica das habilidades necess√°rias."""
        in_degree = {skill: 0 for skill in self.required_skills}

        for skill in self.required_skills:
            for prereq in self.skills_db[skill]['Pre_Reqs']:
                if prereq in in_degree:
                    in_degree[skill] += 1

        queue = [s for s in self.required_skills if in_degree[s] == 0]
        result = []

        while queue:
            current = queue.pop(0)
            result.append(current)

            for skill in self.required_skills:
                if current in self.skills_db[skill]['Pre_Reqs']:
                    in_degree[skill] -= 1
                    if in_degree[skill] == 0:
                        queue.append(skill)

        return result

    def _calculate_minimum_path(self) -> Tuple[int, int]:
        """Calcula caminho m√≠nimo necess√°rio (sem otimiza√ß√£o de valor)."""
        acquired = set()
        total_time = 0
        total_complexity = 0

        topo_order = self._topological_sort()

        for skill_id in topo_order:
            if skill_id not in acquired:
                skill = self.skills_db[skill_id]
                total_time += skill['Tempo']
                total_complexity += skill['Complexidade']
                acquired.add(skill_id)

        return total_time, total_complexity

    def _prune_dominated_states(self, states: List[Dict]) -> List[Dict]:
        """
        Poda mais agressiva de estados dominados.

        MELHORIA: Mant√©m apenas top N estados por valor para economizar mem√≥ria.
        """
        if len(states) <= self.max_states_per_cell:
            return states

        # Ordena por valor decrescente
        states.sort(key=lambda x: x['valor'], reverse=True)

        # Mant√©m apenas os melhores
        pruned = states[:self.max_states_per_cell]

        return pruned

    def solve_deterministic(self, max_time: int, max_complexity: int) -> Dict:
        """
        Resolve o problema de forma determin√≠stica usando DP.

        Returns:
            Dict com solu√ß√£o √≥tima ou mensagem de erro
        """
        print("\n   Executando DP determin√≠stico...")

        # dp[(t, c)] = lista de estados n√£o-dominados
        dp = defaultdict(list)
        dp[(0, 0)].append({'valor': 0, 'skills': frozenset(), 'path': []})

        topo_order = self._topological_sort()

        for skill_id in topo_order:
            skill = self.skills_db[skill_id]
            new_dp = defaultdict(list)

            # Copia estados antigos
            for key, states in dp.items():
                new_dp[key].extend(states)

            # Adiciona transi√ß√µes
            for (t, c), states in dp.items():
                for state in states:
                    # Verifica pr√©-requisitos
                    prereqs_satisfied = all(
                        p in state['skills'] for p in skill['Pre_Reqs']
                    )

                    if not prereqs_satisfied or skill_id in state['skills']:
                        continue

                    new_t = t + skill['Tempo']
                    new_c = c + skill['Complexidade']

                    if new_t <= max_time and new_c <= max_complexity:
                        new_state = {
                            'valor': state['valor'] + skill['Valor'],
                            'skills': state['skills'] | {skill_id},
                            'path': state['path'] + [skill_id]
                        }
                        new_dp[(new_t, new_c)].append(new_state)

            # Poda estados dominados
            for key in new_dp:
                new_dp[key] = self._prune_dominated_states(new_dp[key])

            dp = new_dp

        # Encontra melhor solu√ß√£o com target
        best_value = -1
        best_solution = None

        for states in dp.values():
            for state in states:
                if self.target in state['skills'] and state['valor'] > best_value:
                    best_value = state['valor']
                    best_solution = state

        if best_solution:
            return {
                'success': True,
                'path': best_solution['path'],
                'total_value': best_solution['valor'],
                'total_time': sum(self.skills_db[s]['Tempo'] for s in best_solution['path']),
                'total_complexity': sum(self.skills_db[s]['Complexidade'] for s in best_solution['path'])
            }

        return {
            'success': False,
            'message': f'Imposs√≠vel atingir {self.target} com T‚â§{max_time}, C‚â§{max_complexity}'
        }

    def solve_with_uncertainty(self, max_time: int, max_complexity: int, 
                               n_simulations: int = 1000) -> Dict:
        """
        Resolve com incerteza usando Monte Carlo.

        MELHORIA: Adiciona an√°lise estat√≠stica detalhada.
        """
        print(f"\nüèîÔ∏è Executando {n_simulations} simula√ß√µes Monte Carlo...")

        # Primeiro obt√©m solu√ß√£o determin√≠stica
        det_solution = self.solve_deterministic(max_time, max_complexity)

        if not det_solution['success']:
            return det_solution

        path = det_solution['path']
        simulated_values = []

        np.random.seed(GLOBAL_SEED)

        for i in range(n_simulations):
            total_value = 0
            for skill_id in path:
                base_value = self.skills_db[skill_id]['Valor']
                # Valor varia ¬±10%
                simulated_value = base_value * np.random.uniform(0.9, 1.1)
                total_value += simulated_value

            simulated_values.append(total_value)

        return {
            'success': True,
            'path': path,
            'deterministic_value': det_solution['total_value'],
            'expected_value': np.mean(simulated_values),
            'std_value': np.std(simulated_values),
            'min_value': np.min(simulated_values),
            'max_value': np.max(simulated_values),
            'simulations': simulated_values,
            'total_time': det_solution['total_time'],
            'total_complexity': det_solution['total_complexity']
        }

    def plot_monte_carlo_distribution(self, simulations: List[float], 
                                      filename: str = 'desafio1_monte_carlo.png'):
        """
        MELHORIA: Visualiza distribui√ß√£o Monte Carlo.
        """
        if not MATPLOTLIB_AVAILABLE:
            print("‚ö†Ô∏è matplotlib n√£o dispon√≠vel - pulando gr√°fico")
            return

        plt.figure(figsize=(10, 6))
        plt.hist(simulations, bins=50, alpha=0.7, color='#2E86AB', edgecolor='black')

        mean_val = np.mean(simulations)
        std_val = np.std(simulations)

        plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, 
                   label=f'M√©dia: {mean_val:.2f}')
        plt.axvline(mean_val - std_val, color='orange', linestyle=':', linewidth=1.5,
                   label=f'¬±1œÉ: [{mean_val-std_val:.2f}, {mean_val+std_val:.2f}]')
        plt.axvline(mean_val + std_val, color='orange', linestyle=':', linewidth=1.5)

        plt.xlabel('Valor Total')
        plt.ylabel('Frequ√™ncia')
        plt.title('Distribui√ß√£o de Valores - Simula√ß√£o Monte Carlo (n=1000)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(filename, dpi=300)
        print(f"‚úÖ Gr√°fico salvo: {filename}")
        plt.close()

    def check_feasibility(self, max_time: int, max_complexity: int) -> Tuple[bool, str]:
        """Verifica viabilidade das restri√ß√µes."""
        if self.min_feasible_time <= max_time and self.min_feasible_complexity <= max_complexity:
            return True, "Restri√ß√µes vi√°veis"

        return False, (f"Restri√ß√µes muito r√≠gidas! "
                      f"M√≠nimo necess√°rio: T‚â•{self.min_feasible_time}, "
                      f"C‚â•{self.min_feasible_complexity}")


def run_challenge1():
    """Executa Desafio 1 completo com todas as melhorias."""
    print_header("1Ô∏è‚É£ DESAFIO 1: CAMINHO DE VALOR M√ÅXIMO")

    solver = ImprovedMaxValuePathDP(SKILLS_DATABASE, TARGET_SKILL)

    # Verifica viabilidade
    is_feasible, msg = solver.check_feasibility(MAX_TIME, MAX_COMPLEXITY)
    print(f"\nüìä Viabilidade: {msg}")

    # Usa limites ajustados se necess√°rio
    if USE_RELAXED_CONSTRAINTS and not is_feasible:
        time_limit = solver.min_feasible_time + 50
        complexity_limit = solver.min_feasible_complexity + 6
        print(f"\n‚öôÔ∏è Usando limites ajustados: T‚â§{time_limit}, C‚â§{complexity_limit}")
    else:
        time_limit = MAX_TIME
        complexity_limit = MAX_COMPLEXITY

    # Solu√ß√£o determin√≠stica
    start = time.time()
    det_result = solver.solve_deterministic(time_limit, complexity_limit)
    det_time = time.time() - start

    if det_result['success']:
        print(f"\n‚úÖ SOLU√á√ÉO DETERMIN√çSTICA (tempo: {det_time:.4f}s):")
        print(f"  Caminho: {' ‚Üí '.join(det_result['path'])}")
        print(f"  Valor Total: {det_result['total_value']}")
        print(f"  Tempo: {det_result['total_time']}h")
        print(f"  Complexidade: {det_result['total_complexity']}")
    else:
        print(f"\n‚ùå {det_result['message']}")
        return

    # Monte Carlo
    start = time.time()
    mc_result = solver.solve_with_uncertainty(time_limit, complexity_limit, N_MONTE_CARLO)
    mc_time = time.time() - start

    print(f"\nüé≤ AN√ÅLISE MONTE CARLO (tempo: {mc_time:.4f}s):")
    print(f"  E[Valor]: {mc_result['expected_value']:.2f}")
    print(f"  œÉ(Valor): {mc_result['std_value']:.2f}")
    print(f"  Range: [{mc_result['min_value']:.2f}, {mc_result['max_value']:.2f}]")
    print(f"  Coef. Varia√ß√£o: {mc_result['std_value']/mc_result['expected_value']*100:.2f}%")

    # Compara√ß√£o
    diff = mc_result['expected_value'] - det_result['total_value']
    print(f"\nüìä COMPARA√á√ÉO:")
    print(f"  Determin√≠stico: {det_result['total_value']}")
    print(f"  Estoc√°stico E[V]: {mc_result['expected_value']:.2f}")
    print(f"  Diferen√ßa: {diff:+.2f} ({diff/det_result['total_value']*100:+.2f}%)")

    # Gera gr√°fico
    solver.plot_monte_carlo_distribution(mc_result['simulations'])

    return mc_result


if __name__ == "__main__":
    run_challenge1()
